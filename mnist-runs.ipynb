{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = 'cuda'\n",
    "transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "datasets = {\n",
    "    'train': MNIST(root='data', train=True, download=True, transform=transform),\n",
    "    'test': MNIST(root='data', train=False, download=True, transform=transform)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.nn import Flatten,  Sequential\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from model.dropconnect import DropConnectLinear, DropConnectBatchAverage\n",
    "\n",
    "class Perceptron(Module):\n",
    "    def __init__(self, input_features: int, hidden_dimension: int, output_features: int, p: float):\n",
    "        super().__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.layers = Sequential(\n",
    "            Linear(input_features, hidden_dimension),\n",
    "            ReLU(),\n",
    "            Dropout(p),\n",
    "            Linear(hidden_dimension, output_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        input = self.flatten(input)\n",
    "        return self.layers(input)\n",
    "            \n",
    "\n",
    "class DropConnectPerceptron(Module):\n",
    "    def __init__(self, input_features: int, hidden_dimension: int, output_features: int, p: float):\n",
    "        super().__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.layers = Sequential(\n",
    "            DropConnectLinear(input_features, hidden_dimension, p=p, max_batch_size=256),\n",
    "            ReLU(),\n",
    "            DropConnectBatchAverage(),\n",
    "            DropConnectLinear(hidden_dimension, output_features, p=p, max_batch_size=256),\n",
    "            ReLU(),\n",
    "            DropConnectBatchAverage()\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        input = self.flatten(input)\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "torch.set_float32_matmul_precision('high')   \n",
    "\n",
    "from uuid import uuid4\n",
    "from utils import run\n",
    "from metrics import Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': DataLoader(dataset=datasets['train'],batch_size=64,shuffle=True, pin_memory=True, pin_memory_device=device, num_workers=4),\n",
    "    'test': DataLoader(dataset=datasets['test'],batch_size=64,shuffle=False, pin_memory=True, pin_memory_device=device, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = uuid4()\n",
    "model = Perceptron(784, 512, 10, p=0.3).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()\n",
    "compiled = torch.compile(model)\n",
    "\n",
    "summary = Summary(name=model.__class__.__name__, id=experiment)\n",
    "run(compiled, optimizer, criterion, device, loaders, summary, epochs=50)\n",
    "\n",
    "model = DropConnectPerceptron(784, 512, 10, p=0.3).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()\n",
    "compiled = torch.compile(model)\n",
    "\n",
    "summary = Summary(name=model.__class__.__name__, id=experiment)\n",
    "run(compiled, optimizer, criterion, device, loaders, summary, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
